

#### Take a backup of the etcd cluster and save it to /opt/etcd-backup.db.

Weight: 10

```
controlplane ~ ➜  export ETCDCTL_API=3

controlplane ~ ➜  etcdctl snapshot -h

controlplane ~ ✖ ls /etc/kubernetes/pki/etcd/ca.crt  
ca.key  healthcheck-client.crt  healthcheck-client.key  peer.crt  peer.key  server.crt  server.key

controlplane ~ ➜  etcdctl snapshot save --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --endpoints=127.0.0.1:2379 --key=/etc/kubernetes/pki/etcd/server.key  /opt/etcd-backup.db

``` 


#### Create a Pod called redis-storage with image: redis:alpine with a Volume of type emptyDir that lasts for the life of the Pod.

Weight: 10

#### Specs on the below. /  Pod named 'redis-storage' created /   Pod 'redis-storage' uses Volume type of emptyDir / Pod 'redis-storage' uses volumeMount with mountPath = /data/redis

``` 
controlplane ~ ✖ kubectl apply -f empty_pod.yaml 
pod/redis-storage created

controlplane ~ ➜  cat empty_pod.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: redis-storage
spec:
  containers:
  - image: redis:alpine
    name: redis-storage
    volumeMounts:
    - mountPath: /data/redis
      name: redis-storage
  volumes:
  - name: redis-storage
    emptyDir: {}

controlplane ~ ➜  kubectl get pods
NAME            READY   STATUS    RESTARTS   AGE
redis-storage   1/1     Running   0          50s

controlplane ~ ✖ kubectl exec --stdin --tty redis-storage -- /bin/sh
/data # 

/data # df -h 
Filesystem                Size      Used Available Use% Mounted on
overlay                 969.0G    196.6G    772.4G  20% /
tmpfs                   102.3G         0    102.3G   0% /proc/acpi
udev                    102.3G         0    102.3G   0% /proc/keys
udev                    102.3G         0    102.3G   0% /proc/timer_list
udev                    102.3G         0    102.3G   0% /proc/sched_debug
tmpfs                   102.3G         0    102.3G   0% /proc/scsi
tmpfs                    64.0M         0     64.0M   0% /dev
tmpfs                   102.3G         0    102.3G   0% /sys/fs/cgroup
.                       969.0G    196.6G    772.4G  20% /data
/dev/sda1               969.0G    196.6G    772.4G  20% /data/redis
/dev/sda1               969.0G    196.6G    772.4G  20% /etc/hosts
/dev/sda1               969.0G    196.6G    772.4G  20% /dev/termination-log
.                       969.0G    196.6G    772.4G  20% /etc/hostname
.                       969.0G    196.6G    772.4G  20% /etc/resolv.conf
shm                      64.0M         0     64.0M   0% /dev/shm
tmpfs                   204.5G     12.0K    204.5G   0% /run/secrets/kubernetes.io/serviceaccount
udev                    102.3G         0    102.3G   0% /dev/null
udev                    102.3G         0    102.3G   0% /dev/random
udev                    102.3G         0    102.3G   0% /dev/full
udev                    102.3G         0    102.3G   0% /dev/tty
udev                    102.3G         0    102.3G   0% /dev/zero
udev                    102.3G         0    102.3G   0% /dev/urandom
udev                    102.3G         0    102.3G   0% /proc/kcore
tmpfs                   102.3G         0    102.3G   0% /sys/firmware

/data # uname -a
Linux redis-storage 5.4.0-1092-gcp #101~18.04.1-Ubuntu SMP Mon Oct 17 18:29:06 UTC 2022 x86_64 Linux
/data # ls -lh  /data/redis
total 0      
/data # exit
```

#### Create a new pod called super-user-pod with image busybox:1.28. Allow the pod to be able to set system_time.
Weight: 8
#### The container should sleep for 4800 seconds. / Pod: super-user-pod /  Container Image: busybox:1.28 /SYS_TIME capabilities for the conatiner?

```
controlplane ~ ➜  kubectl run super-user-pod --image=busybox:1.28 --dry-run=client -o yaml --command -- sleep 4800 > super-user-pod.yaml

controlplane ~ ➜  vim super-user-pod.yaml 

controlplane ~ ➜  kubectl apply -f super-user-pod.yaml 
pod/super-user-pod created

controlplane ~ ➜  kubectl get pods
NAME             READY   STATUS    RESTARTS   AGE
redis-storage    1/1     Running   0          3m24s
super-user-pod   1/1     Running   0          4s

controlplane ~ ➜  cat super-user-pod.yaml 
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: super-user-pod
  name: super-user-pod
spec:
  containers:
  - command:
    - sleep
    - "4800"
    image: busybox:1.28
    name: super-user-pod
    securityContext:
      capabilities:
        add: ["SYS_TIME"]
```

#### A pod definition file is created at /root/CKA/use-pv.yaml. Make use of this manifest file and mount the persistent volume called pv-1. Ensure the pod is running and the PV is bound.

Weight: 12

#### mountPath: /data / persistentVolumeClaim Name: my-pvc /  persistentVolume Claim configured correctly /  pod using the correct mountPath /  pod using the persistent volume claim?
``` 
ontrolplane ~ ➜  kubectl get pv
NAME   CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE
pv-1   10Mi       RWO            Retain           Available                                   17m

controlplane ~ ➜  cat pvc
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: my-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Mi

controlplane ~ ➜  kubectl apply -f pvc 
persistentvolumeclaim/my-pvc created

controlplane ~ ➜  kubectl get pvc
NAME     STATUS   VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE
my-pvc   Bound    pv-1     10Mi       RWO                           4s


controlplane ~ ➜  kubectl get pv
NAME   CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM            STORAGECLASS   REASON   AGE
pv-1   10Mi       RWO            Retain           Bound    default/my-pvc                           19m

controlplane ~ ➜  cat CKA/use-pv.yaml 
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: use-pv
  name: use-pv
spec:
  containers:
  - image: nginx
    name: use-pv
    volumeMounts:
      - mountPath: "/data"
        name: use-pv
  volumes:
    - name: use-pv
      persistentVolumeClaim:
        claimName: my-pvc

controlplane ~ ➜  vim CKA/use-pv.yaml 

controlplane ~ ➜  kubectl apply -f CKA/use-pv.yaml 
pod/use-pv created

controlplane ~ ➜  kubectl get pods
NAME             READY   STATUS              RESTARTS   AGE
redis-storage    1/1     Running             0          30m
super-user-pod   1/1     Running             0          27m
use-pv           0/1     ContainerCreating   0          5s

controlplane ~ ➜  kubectl get pods
NAME             READY   STATUS    RESTARTS   AGE
redis-storage    1/1     Running   0          31m
super-user-pod   1/1     Running   0          27m
use-pv           1/1     Running   0          8s

controlplane ~ ➜  kubectl describe pod use-pv 
Name:         use-pv
Namespace:    default
Priority:     0
Node:         node01/10.6.145.12
Start Time:   Tue, 01 Nov 2022 05:17:06 +0000
Labels:       run=use-pv
Annotations:  <none>
Status:       Running
IP:           10.50.192.3
IPs:
  IP:  10.50.192.3
Containers:
  use-pv:
    Container ID:   containerd://2bfd01d7a66c76fa1c8036d885d63add2a67cc55dc99ed1a685fa0bbe47d05d9
    Image:          nginx
    Image ID:       docker.io/library/nginx@sha256:943c25b4b66b332184d5ba6bb18234273551593016c0e0ae906bab111548239f
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Tue, 01 Nov 2022 05:17:12 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /data from mypd (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-sfphr (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  mypd:
    Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)
    ClaimName:  my-pvc
    ReadOnly:   false
  kube-api-access-sfphr:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age   From               Message
  ----    ------     ----  ----               -------
  Normal  Scheduled  23s   default-scheduler  Successfully assigned default/use-pv to node01
  Normal  Pulling    22s   kubelet            Pulling image "nginx"
  Normal  Pulled     17s   kubelet            Successfully pulled image "nginx" in 4.808326483s
  Normal  Created    17s   kubelet            Created container use-pv
  Normal  Started    17s   kubelet            Started container use-pv
``` 
  
##### Create a new deployment called nginx-deploy, with image nginx:1.16 and 1 replica. Next upgrade the deployment to version 1.17 using rolling update.

Weight: 15

##### Deployment : nginx-deploy. Image: nginx:1.16 / Image: nginx:1.16 / Task: Upgrade the version of the deployment to 1:17 /  Task: Record the changes for the image upgrade

``` 
controlplane ~ ➜  kubectl create deployment nginx-deploy --image=nginx:1.16 --replicas=1
deployment.apps/nginx-deploy created

controlplane ~ ➜  kubectl set image deployment/nginx-deploy nginx=nginx:1.17 --record 
Flag --record has been deprecated, --record will be removed in the future
deployment.apps/nginx-deploy image updated

controlplane ~ ➜  kubectl rollout status deployment/nginx-deploy
deployment "nginx-deploy" successfully rolled out

controlplane ~ ➜  kubectl rollout history deployment nginx-deploy 
deployment.apps/nginx-deploy 
REVISION  CHANGE-CAUSE
1         <none>
2         kubectl set image deployment/nginx-deploy nginx=nginx:1.17 --record=true

controlplane ~ ➜  kubectl describe deployments.apps nginx-deploy 
Name:                   nginx-deploy
Namespace:              default
CreationTimestamp:      Tue, 01 Nov 2022 05:21:03 +0000
Labels:                 app=nginx-deploy
Annotations:            deployment.kubernetes.io/revision: 2
                        kubernetes.io/change-cause: kubectl set image deployment/nginx-deploy nginx=nginx:1.17 --record=true
Selector:               app=nginx-deploy
Replicas:               1 desired | 1 updated | 1 total | 1 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=nginx-deploy
  Containers:
   nginx:
    Image:        nginx:1.17
    Port:         <none>
    Host Port:    <none>
    Environment:  <none>
    Mounts:       <none>
  Volumes:        <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  <none>
NewReplicaSet:   nginx-deploy-75d47c9469 (1/1 replicas created)
Events:
  Type    Reason             Age   From                   Message
  ----    ------             ----  ----                   -------
  Normal  ScalingReplicaSet  99s   deployment-controller  Scaled up replica set nginx-deploy-7cfd4975d6 to 1
  Normal  ScalingReplicaSet  54s   deployment-controller  Scaled up replica set nginx-deploy-75d47c9469 to 1
  Normal  ScalingReplicaSet  47s   deployment-controller  Scaled down replica set nginx-deploy-7cfd4975d6 to 0
  
  ``` 
