1. Inspect the kubelet service and identify the network plugin configured for Kubernetes.

root@controlplane ~ ➜  ps -ef |grep kubelet |grep network --color
root      4263     1  0 04:22 ?        00:00:20 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --config=/var/lib/kubelet/config.yaml --network-plugin=cni --pod-infra-container-image=k8s.gcr.io/pause:3.6

2. What is the path configured with all binaries of CNI supported plugins?
root@controlplane ➜  ls -l /opt/cni/bin/
total 70540
-rwxr-xr-x 1 root root  4159518 May 13  2020 bandwidth
-rwxr-xr-x 1 root root  4671647 May 13  2020 bridge
-rwxr-xr-x 1 root root 12124326 May 13  2020 dhcp
-rwxr-xr-x 1 root root  5945760 May 13  2020 firewall
-rwxr-xr-x 1 root root  3069556 May 13  2020 flannel
-rwxr-xr-x 1 root root  4174394 May 13  2020 host-device
-rwxr-xr-x 1 root root  3614480 May 13  2020 host-local
-rwxr-xr-x 1 root root  4314598 May 13  2020 ipvlan
-rwxr-xr-x 1 root root  3209463 May 13  2020 loopback
-rwxr-xr-x 1 root root  4389622 May 13  2020 macvlan
-rwxr-xr-x 1 root root  3939867 May 13  2020 portmap
-rwxr-xr-x 1 root root  4590277 May 13  2020 ptp
-rwxr-xr-x 1 root root  3392826 May 13  2020 sbr
-rwxr-xr-x 1 root root  2885430 May 13  2020 static
-rwxr-xr-x 1 root root  3356587 May 13  2020 tuning
-rwxr-xr-x 1 root root  4314446 May 13  2020 vlan

3. What is the CNI plugin configured to be used on this kubernetes cluster?
root@controlplane /var/lib/kubelet ➜  ls -l /etc/cni/net.d/
total 4
-rw-r--r-- 1 root root 292 Jul  7 04:23 10-flannel.conflist

4. What binary executable file will be run by kubelet after a container and its associated namespace are created.
root@controlplane /var/lib/kubelet ➜  ls -l /etc/cni/net.d/
total 4
-rw-r--r-- 1 root root 292 Jul  7 04:23 10-flannel.conflist

5. Deploy weave-net networking solution to the cluster.

Replace the default IP address and subnet of weave-net to the 10.50.0.0/16. 
Please check the official weave installation and configuration guide which is available at the top right panel. 

    1. Deploy weave

     2. Wait for the app to run
     
By default, the range of IP addresses and the subnet used by weave-net is 10.32.0.0/12 and it's overlapping with the host system IP addresses.
To know the host system IP address by running ip a command :-

root@controlplane ~ ➜  ip a |grep eth0
2800: eth0@if2801: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UP group default 
    inet 10.5.152.3/24 brd 10.5.152.255 scope global eth0

if we deploy a weave manifest file directly without changing the default IP addresses it will overlap with the host system IP addresses and as a result, 
it's weave pods will go into an Error or CrashLoopBackOff state.

root@controlplane:~# kubectl get po -n kube-system | grep weave
weave-net-6mckb                        1/2     CrashLoopBackOff   6          6m46s

If we will go more deeper and inspect the logs then we can clearly see the issue :-
root@controlplane:~# kubectl logs -n kube-system weave-net-6mckb -c weave
Network 10.32.0.0/12 overlaps with existing route 10.40.56.0/24 on host

root@controlplane ~ ➜  kubectl get po app
NAME   READY   STATUS              RESTARTS   AGE
app    0/1     ContainerCreating   0          11m

root@controlplane ~ ✖ kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')&env.IPALLOC_RANGE=10.50.0.0/16"
serviceaccount/weave-net created
clusterrole.rbac.authorization.k8s.io/weave-net created
clusterrolebinding.rbac.authorization.k8s.io/weave-net created
role.rbac.authorization.k8s.io/weave-net created
rolebinding.rbac.authorization.k8s.io/weave-net created
daemonset.apps/weave-net created

root@controlplane ~ ➜  kubectl get po 
NAME   READY   STATUS    RESTARTS   AGE
app    1/1     Running   0          11m

     
6. What is the POD IP address range configured by weave?
root@controlplane ~ ✖ kubectl logs weave-net-dgkk7 -n kube-system 
error: a container name must be specified for pod weave-net-dgkk7, choose one of: [weave weave-npc] or one of the init containers: [weave-init]

root@controlplane ~ ✖ kubectl logs weave-net-dgkk7 -n kube-system weave 
INFO: 2022/07/07 05:38:35.952978 Command line options: map[conn-limit:200 datapath:datapath db-prefix:/weavedb/weave-net docker-api: expect-npc:true http-addr:127.0.0.1:6784 ipalloc-init:consensus=1 ipalloc-range:10.50.0.0/16 metrics-addr:0.0.0.0:6782 name:46:94:f3:cf:e9:3e nickname:node01 no-dns:true no-masq-local:true port:6783]
INFO: 2022/07/07 05:38:35.953030 weave  2.8.1
INFO: 2022/07/07 05:38:36.898674 Bridge type is bridged_fastdp
INFO: 2022/07/07 05:38:36.898707 Communication between peers is unencrypted.
INFO: 2022/07/07 05:38:36.927522 Our name is 46:94:f3:cf:e9:3e(node01)
INFO: 2022/07/07 05:38:36.927599 Launch detected - using supplied peer list: [10.8.214.6]
INFO: 2022/07/07 05:38:36.927692 Using "no-masq-local" LocalRangeTracker
INFO: 2022/07/07 05:38:36.927748 Checking for pre-existing addresses on weave bridge
INFO: 2022/07/07 05:38:36.928909 [allocator 46:94:f3:cf:e9:3e] No valid persisted data
INFO: 2022/07/07 05:38:36.934074 [allocator 46:94:f3:cf:e9:3e] Initialising via deferred consensus
INFO: 2022/07/07 05:38:36.934134 Sniffing traffic on datapath (via ODP)
INFO: 2022/07/07 05:38:36.935478 ->[10.8.214.6:6783] attempting connection
INFO: 2022/07/07 05:38:36.937007 ->[10.8.214.6:6783|22:0b:25:3d:ff:05(controlplane)]: connection ready; using protocol version 2
INFO: 2022/07/07 05:38:36.937128 overlay_switch ->[22:0b:25:3d:ff:05(controlplane)] using fastdp
INFO: 2022/07/07 05:38:36.937154 ->[10.8.214.6:6783|22:0b:25:3d:ff:05(controlplane)]: connection added (new peer)
INFO: 2022/07/07 05:38:36.937870 Listening for HTTP control messages on 127.0.0.1:6784
INFO: 2022/07/07 05:38:36.937936 Listening for metrics requests on 0.0.0.0:6782
INFO: 2022/07/07 05:38:36.938518 ->[10.8.214.6:6783|22:0b:25:3d:ff:05(controlplane)]: connection fully established
INFO: 2022/07/07 05:38:37.041770 sleeve ->[10.8.214.6:6783|22:0b:25:3d:ff:05(controlplane)]: Effective MTU verified at 1388
INFO: 2022/07/07 05:38:37.129863 [kube-peers] Added myself to peer list &{[{22:0b:25:3d:ff:05 controlplane} {46:94:f3:cf:e9:3e node01}]}
DEBU: 2022/07/07 05:38:37.138908 [kube-peers] Nodes that have disappeared: map[]
INFO: 2022/07/07 05:38:37.243419 adding entry 10.50.192.0/18 to weaver-no-masq-local of 0
INFO: 2022/07/07 05:38:37.243448 added entry 10.50.192.0/18 to weaver-no-masq-local of 0
10.50.192.0
DEBU: 2022/07/07 05:38:37.627777 registering for updates for node delete events
INFO: 2022/07/07 05:38:42.139255 Discovered remote MAC 06:64:87:66:c3:66 at 22:0b:25:3d:ff:05(controlplane)
INFO: 2022/07/07 05:38:42.141579 Discovered remote MAC 12:bb:8e:6d:22:15 at 22:0b:25:3d:ff:05(controlplane)

7. What is the default gateway configured on the PODs scheduled on node01?
Try scheduling a pod on node01 and check ip route output

root@controlplane ~ ✖ kubectl run app --image=busybox --dry-run=client -o yaml -- sleep 1000 
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: app
  name: app
spec:
  containers:
  - args:
    - sleep
    - "1000"
    image: busybox
    name: app
    resources: {}
  dnsPolicy: ClusterFirst
  restartPolicy: Always
status: {}

root@controlplane ~ ➜  kubectl run app --image=busybox --dry-run=client -o yaml -- sleep 1000 > busybox.yaml

root@controlplane ~ ➜  kubectl apply -f busybox.yaml 
pod/app created

root@controlplane ~ ✖ kubectl exec app -- route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         10.50.192.0     0.0.0.0         UG    0      0        0 eth0
10.50.0.0       0.0.0.0         255.255.0.0     U     0      0        0 eth0

root@controlplane ~ ➜  kubectl exec app -- ip route
default via 10.50.192.0 dev eth0 
10.50.0.0/16 dev eth0 scope link  src 10.50.192.1 
